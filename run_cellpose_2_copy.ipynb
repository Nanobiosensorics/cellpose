{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt8hgC7rniP8",
    "outputId": "677fa3d0-952f-4490-f5bb-4ef1ad0b0469"
   },
   "outputs": [],
   "source": [
    "# !nvcc --version\n",
    "# !nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "from data_loader import CellDataset, split_dataset\n",
    "from cellpose import models\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "\n",
    "def get_image_ids(path):\n",
    "    pattern = r'^(\\d+[_-]\\d+(?:[_-]\\d+)?)'\n",
    "    if os.path.isdir(path):\n",
    "        ids = []\n",
    "        for filename in os.listdir(path):\n",
    "            match = re.match(pattern, filename)\n",
    "            if match is not None:\n",
    "                ids.append(match.group(1))\n",
    "        ids = sorted(list(set(ids)))\n",
    "    else:\n",
    "        split = path.split(os.sep)\n",
    "        if len(split) <= 1:\n",
    "            split = path.split('/')\n",
    "        parts, name = split[:-1], split[-1]\n",
    "        name = re.match(pattern, name)\n",
    "        if name is None:\n",
    "            raise Exception('Experiment id not found in filename!')\n",
    "        ids = [name.group(1)]\n",
    "        path = os.path.join(*parts)\n",
    "        if os.sep == '/':\n",
    "            path = '/' + path\n",
    "    return path, ids\n",
    "\n",
    "def get_tif(path, idx):\n",
    "    files = [name for name in os.listdir(path) if name.endswith('5.tif') and idx in name]\n",
    "    return None if len(files) == 0 else files[0]\n",
    "\n",
    "def get_smlm_file(path, idx):\n",
    "    files = [name for name in os.listdir(path) if name.endswith('.txt') and idx in name]\n",
    "    return None if len(files) == 0 else files[0]\n",
    "\n",
    "def get_smlm_aligned_file(path, idx):\n",
    "    files = [name for name in os.listdir(path) if idx in name and 'ClusterData' in name]\n",
    "    return None if len(files) == 0 else files[0]\n",
    "\n",
    "def get_srrf_file(path, idx):\n",
    "    files = [name for name in os.listdir(path) if idx in name and 'segmResultsPRED' in name]\n",
    "    return None if len(files) == 0 else files[0]\n",
    "\n",
    "def get_seg_file(path, idx):\n",
    "    files = [name for name in os.listdir(path) if idx in name and 'seg.npy' in name]\n",
    "    return None if len(files) == 0 else files[0]\n",
    "\n",
    "def get_raw_srrf_file(path, idx):\n",
    "    files = [name for name in os.listdir(path) if idx in name and name.endswith('.ome.tif')]\n",
    "    return None if len(files) == 0 else files[0]\n",
    "\n",
    "def get_sample(path, idx):\n",
    "    if os.path.isfile(path):\n",
    "        path = os.path.join(*path.split('/')[:-1])\n",
    "    return { \n",
    "            'img' : os.path.join(path, f) if (f := get_tif(path, idx)) is not None else None, \n",
    "            'smlm': os.path.join(path, f) if (f := get_smlm_file(path, idx)) is not None else None, \n",
    "            'smlm_aligned': os.path.join(path, f) if (f := get_smlm_aligned_file(path, idx)) is not None else None, \n",
    "            'srrf': os.path.join(path, f) if (f := get_srrf_file(path, idx)) is not None else None,\n",
    "            'raw-srrf': os.path.join(path, f) if (f := get_raw_srrf_file(path, idx)) is not None else None,\n",
    "            'seg': os.path.join(path, f) if (f := get_seg_file(path, idx)) is not None else None\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQI4aUxCjz3n",
    "outputId": "804d0459-b120-4298-9b4c-87a9ca26401c"
   },
   "outputs": [],
   "source": [
    "initial_model = \"cyto\" #@param ['cyto','nuclei','tissuenet','livecell','cyto2','CP','CPx','TN1','TN2','TN3','LC1','LC2','LC3','LC4','scratch']\n",
    "model_dir = \"./\"\n",
    "model_name = \"single_cell_params_test.pt\" #@param {type:\"string\"}\n",
    "n_epochs =  100#@param {type:\"number\"}\n",
    "learning_rate = 0.01 \n",
    "weight_decay = 0.0001\n",
    "batch_size = 8\n",
    "chan = 0\n",
    "chan2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../nc_data/240229-SRRF-SMLM-data-WF-and-TIRF-imaging/1.1.1-STORM-PooledPlasma-ch640/'\n",
    "data_path, ids = get_image_ids(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "\n",
    "for idx in ids:\n",
    "    sample = get_sample(data_path, idx)\n",
    "    paths.append(sample['img'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_percent = 0.2\n",
    "\n",
    "random.shuffle(paths)\n",
    "\n",
    "n_val = int(len(paths) * val_percent)\n",
    "n_train = len(paths) - n_val\n",
    "train_paths, test_paths = paths[:n_train], paths[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from cellpose import dynamics, transforms, io, utils\n",
    "\n",
    "def split_dataset(dirs, test_split=0.2, mask_filter='_seg.npy'):\n",
    "    train_paths = []\n",
    "    test_paths = []\n",
    "    np.random.seed(0)\n",
    "    \n",
    "    for dir in set(map(lambda k: k[:-3], dirs)) :\n",
    "        sub_dirs = list(filter(lambda k: dir in k, dirs))\n",
    "        imgs = []\n",
    "        for pth in sub_dirs:\n",
    "            imgs.extend(io.get_image_files(pth, '_seg.npy'))    \n",
    "        idx_full = np.arange(len(imgs))\n",
    "        np.random.shuffle(idx_full)\n",
    "        idx = int((1 - test_split) * len(imgs))\n",
    "        train_paths.extend([imgs[i] for i in idx_full[:idx]])\n",
    "        test_paths.extend([imgs[i] for i in idx_full[idx:]])\n",
    "        \n",
    "    return train_paths, test_paths\n",
    "\n",
    "class CellDataset(Dataset):\n",
    "    def __init__(self, dir=None, paths=None, train=True, channels=[0,0], mask_filter='_seg.npy', imf=None, look_one_level_down=False, generate_flows=False):\n",
    "        super().__init__()\n",
    "        self.ids = []\n",
    "        self.train = train\n",
    "        self.channels = channels\n",
    "        self.diam_mean = 30\n",
    "        self.scale_range = 0.5\n",
    "        self.rescale = True\n",
    "        self.unet = True\n",
    "        self.image_names = []\n",
    "        self.label_names = []\n",
    "        self.flow_names = []\n",
    "        self.diam_scale = []\n",
    "        \n",
    "        if paths == None and dir == None:\n",
    "            print(\"Either dir or paths is mandatory at initialization!\")\n",
    "            return\n",
    "        \n",
    "        if dir != None:\n",
    "            if type(dir) == str:\n",
    "                dir = [dir]\n",
    "            \n",
    "            for path in dir:\n",
    "                image_names = io.get_image_files(path, mask_filter, imf=imf, look_one_level_down=look_one_level_down)\n",
    "                self.image_names.extend(image_names)\n",
    "                \n",
    "        elif paths != None:\n",
    "            self.image_names = paths.copy()\n",
    "\n",
    "        label_names, flow_names = io.get_label_files(self.image_names, mask_filter, imf=imf)\n",
    "        \n",
    "        if len(label_names) != len(flow_names) and generate_flows:\n",
    "            self.generate_flows(self.image_names, label_names, flow_names)\n",
    "            label_names, flow_names = io.get_label_files(self.image_names, mask_filter, imf=imf)\n",
    "            \n",
    "        self.label_names.extend(label_names)\n",
    "        self.flow_names.extend(flow_names)\n",
    "        self.ids = list(range(len(self.image_names)))\n",
    "        \n",
    "    def set_train_params(self, diam_scale, diam_mean=30, scale_range=1.0, rescale=True, unet=True):\n",
    "        self.diam_scale = diam_scale\n",
    "        self.diam_mean = diam_mean\n",
    "        self.scale_range = scale_range\n",
    "        self.rescale = rescale\n",
    "        self.unet = unet\n",
    "\n",
    "    def load_raw(self, img_id):\n",
    "        if self.train:\n",
    "            # image\n",
    "            image = self.get_image(img_id)\n",
    "            # label\n",
    "            target = self.get_target(img_id) if self.train else {}\n",
    "            image, target = self.transform(img_id, image, target, raw=True)\n",
    "            return image, target\n",
    "        else:\n",
    "            image = self.get_image(img_id)\n",
    "            image, pre_info = self.transform(img_id, image, raw=True)\n",
    "            return image, pre_info\n",
    "\n",
    "    def __getitem__(self, img_id):\n",
    "        if self.train:\n",
    "            # image\n",
    "            image = self.get_image(img_id)\n",
    "            # label\n",
    "            target = self.get_target(img_id) if self.train else {}\n",
    "            image, target = self.transform(img_id, image, target)\n",
    "            return image, target\n",
    "        else:\n",
    "            image = self.get_image(img_id)\n",
    "            image, pre_info = self.transform(img_id, image)\n",
    "            return image, pre_info\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "\n",
    "    def get_image(self, img_id):\n",
    "        image = io.imread(self.image_names[img_id])\n",
    "        return [ image ]\n",
    "    \n",
    "    def get_image_files(self):\n",
    "        return self.image_names\n",
    "    \n",
    "    def get_label_files(self):\n",
    "        return self.label_names, self.flow_names\n",
    "\n",
    "    @staticmethod\n",
    "    def convert_to_xyxy(box):\n",
    "        new_box = torch.zeros_like(box)\n",
    "        new_box[:, 0] = box[:, 0]\n",
    "        new_box[:, 1] = box[:, 1]\n",
    "        new_box[:, 2] = box[:, 0] + box[:, 2]\n",
    "        new_box[:, 3] = box[:, 1] + box[:, 3]\n",
    "        return new_box # new_box format: (xmin, ymin, xmax, ymax)\n",
    "    \n",
    "    def generate_flows(self, image_names, label_names, flow_names, use_gpu=True):\n",
    "        for image_name, label_name in zip(image_names[len(flow_names):], label_names[len(flow_names):]):\n",
    "            masks = io.imread(label_name)\n",
    "            masks = self.mask_convert(masks)\n",
    "            dynamics.labels_to_flows([masks], files=[image_name], use_gpu=use_gpu)\n",
    "\n",
    "    def get_target(self, img_id):\n",
    "        # return target.shape: [4, Ly, Lx]\n",
    "        # target[0] is masks, target[1] is cell_probability, target[2] is flow Y, target[3] is flow X.Q\n",
    "        if len(self.flow_names) > img_id:\n",
    "            masks = io.imread(self.flow_names[img_id])\n",
    "        else:\n",
    "            masks = io.imread(self.label_names[img_id])\n",
    "            masks = self.mask_convert(masks)\n",
    "\n",
    "        # mask to flows, flows.shape: list of [4 x Ly x Lx] arrays\n",
    "        flows = dynamics.labels_to_flows([masks], use_gpu=True)\n",
    "        target = flows[0]\n",
    "        return [target]\n",
    "\n",
    "    def transform(self, img_id, img, label=None, raw=False):\n",
    "        # dataset argument\n",
    "        # step1: reshape and normalize data\n",
    "        tr, ts, rn = transforms.reshape_and_normalize_data(img, channels=self.channels, normalize=True)\n",
    "        if raw:\n",
    "            return tr[0], label[0]\n",
    "        # step2: random rotate and resize\n",
    "        if self.train and label is not None:\n",
    "            rsc = self.diam_scale[img_id] / self.diam_mean if self.rescale else 1.0\n",
    "            imgi, lbl, scale = transforms.random_rotate_and_resize(tr, [label[0][1:]], scale_range=self.scale_range, rescale=[rsc], unet=self.unet)\n",
    "            if self.unet and lbl.shape[1]>1 and self.rescale:\n",
    "                lbl[:,1] *= scale[:,np.newaxis,np.newaxis]**2#diam_batch[:,np.newaxis,np.newaxis]**2\n",
    "            img, label = map(torch.from_numpy, [imgi, lbl])\n",
    "            return torch.squeeze(img), torch.squeeze(label)\n",
    "        else:\n",
    "            # eval transform\n",
    "            img, *pre_info  = transforms.pad_image_ND(img)\n",
    "            img = torch.from_numpy(img)\n",
    "            return torch.squeeze(img), pre_info\n",
    "\n",
    "    def mask_convert(self, masks):\n",
    "        if masks.ndim == 3:\n",
    "            return masks\n",
    "        else:\n",
    "            return masks[np.newaxis, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_paths, test_paths = split_dataset(paths, 0.2)\n",
    "train_ds = CellDataset(paths=train_paths, generate_flows=True, mask_filter='_cp_masks')\n",
    "test_ds = CellDataset(paths=test_paths, generate_flows=True, mask_filter='_cp_masks')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cdH0j8-L6FuB"
   },
   "source": [
    "## Evaluate on test data (optional)\n",
    "\n",
    "If you have test data, check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0AGsH5p6K6S",
    "outputId": "3f67063a-2197-4ec2-8619-0b52c98fd0ee"
   },
   "outputs": [],
   "source": [
    "# get files (during training, test_data is transformed so we will load it again)\n",
    "output = io.load_train_test_data(test_dir, mask_filter='_seg.npy')\n",
    "test_data, test_labels = output[:2]\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, \n",
    "                   channels=[chan, chan2],\n",
    "                   diameter=diam_labels)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print('')\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "K8tZ8uYR-IFW"
   },
   "source": [
    "plot masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z2ac5gtr-HPq",
    "outputId": "65c96437-85e4-42cf-8d4b-414b6ba98c0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,8), dpi=150)\n",
    "for k,im in enumerate(test_data):\n",
    "    img = im.copy()\n",
    "    plt.subplot(3,len(train_files), k+1)\n",
    "    img = np.vstack((img, np.zeros_like(img)[:1]))\n",
    "    img = img.transpose(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('image')\n",
    "\n",
    "    plt.subplot(3,len(train_files), len(train_files) + k+1)\n",
    "    plt.imshow(masks[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('predicted labels')\n",
    "\n",
    "    plt.subplot(3,len(train_files), 2*len(train_files) + k+1)\n",
    "    plt.imshow(test_labels[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('true labels')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

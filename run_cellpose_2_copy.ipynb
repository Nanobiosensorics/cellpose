{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt8hgC7rniP8",
    "outputId": "677fa3d0-952f-4490-f5bb-4ef1ad0b0469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "# !nvcc --version\n",
    "# !nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "from data_loader import CellDataset, split_dataset\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQI4aUxCjz3n",
    "outputId": "804d0459-b120-4298-9b4c-87a9ca26401c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default advanced parameters enabled\n"
     ]
    }
   ],
   "source": [
    "#@markdown ###Path to images and masks:\n",
    "\n",
    "train_dir = \"/media/balint/st1/data/cell-counting/annotated/\" #@param {type:\"string\"}\n",
    "test_dir = \"\" #@param {type:\"string\"}\n",
    "model_dir = \"./\"\n",
    "#Define where the patch file will be saved\n",
    "base = \"/content\"\n",
    "\n",
    "# model name and path\n",
    "#@markdown ###Name of the pretrained model to start from and new model name:\n",
    "from cellpose import models\n",
    "initial_model = \"cyto\" #@param ['cyto','nuclei','tissuenet','livecell','cyto2','CP','CPx','TN1','TN2','TN3','LC1','LC2','LC3','LC4','scratch']\n",
    "model_name = \"single_cell_params_test.pt\" #@param {type:\"string\"}\n",
    "\n",
    "# other parameters for training.\n",
    "#@markdown ###Training Parameters:\n",
    "#@markdown Number of epochs:\n",
    "n_epochs =  100#@param {type:\"number\"}\n",
    "\n",
    "Channel_to_use_for_training = \"Grayscale\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "# @markdown ###If you have a secondary channel that can be used for training, for instance nuclei, choose it here:\n",
    "\n",
    "Second_training_channel= \"None\" #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "\n",
    "#@markdown ###Advanced Parameters\n",
    "\n",
    "Use_Default_Advanced_Parameters = True #@param {type:\"boolean\"}\n",
    "#@markdown ###If not, please input:\n",
    "learning_rate = 0.1 #@param {type:\"number\"}\n",
    "weight_decay = 0.0001 #@param {type:\"number\"}\n",
    "\n",
    "if (Use_Default_Advanced_Parameters): \n",
    "  print(\"Default advanced parameters enabled\")\n",
    "  learning_rate = 0.01 \n",
    "  weight_decay = 0.0001\n",
    "  \n",
    "#here we check that no model with the same name already exist, if so delete\n",
    "model_path = train_dir + 'models/'\n",
    "if os.path.exists(model_path+'/'+model_name):\n",
    "  print(\"!! WARNING: \"+model_name+\" already exists and will be deleted in the following cell !!\")\n",
    "  \n",
    "if len(test_dir) == 0:\n",
    "  test_dir = None\n",
    "\n",
    "# Here we match the channel to number\n",
    "if Channel_to_use_for_training == \"Grayscale\":\n",
    "  chan = 0\n",
    "elif Channel_to_use_for_training == \"Blue\":\n",
    "  chan = 3\n",
    "elif Channel_to_use_for_training == \"Green\":\n",
    "  chan = 2\n",
    "elif Channel_to_use_for_training == \"Red\":\n",
    "  chan = 1\n",
    "\n",
    "\n",
    "if Second_training_channel == \"Blue\":\n",
    "  chan2 = 3\n",
    "elif Second_training_channel == \"Green\":\n",
    "  chan2 = 2\n",
    "elif Second_training_channel == \"Red\":\n",
    "  chan2 = 1\n",
    "elif Second_training_channel == \"None\":\n",
    "  chan2 = 0\n",
    "\n",
    "if initial_model=='scratch':\n",
    "  initial_model = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/A1',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/A2',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/A3',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/A4',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/B1',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/B2',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/B3',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/B4',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/C1',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/C2',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/C3',\n",
       " '/media/balint/st3/projects/data/classification_datasets/lognorm-images/fibronectin/20210526_MDAMB231_fn/C4']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_paths = []\n",
    "with open(\"./file_paths_2.txt\", \"r\") as fp:\n",
    "    data_paths = fp.read().strip().split('\\n')\n",
    "data_paths = data_paths\n",
    "data_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths, test_paths = split_dataset(data_paths, 0.25)\n",
    "train_ds = CellDataset(paths=train_paths, generate_flows=True)\n",
    "test_ds = CellDataset(paths=test_paths, generate_flows=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcYskYudMajM",
    "outputId": "ed4dce67-190e-4d52-9a70-bcbc76be4b65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-12 19:27:15,924 [INFO] WRITING LOG OUTPUT TO /home/balint/.cellpose/run.log\n",
      "2023-08-12 19:27:15,925 [INFO] \n",
      "cellpose version: \t2.2 \n",
      "platform:       \tlinux \n",
      "python version: \t3.8.15 \n",
      "torch version:  \t2.0.0+cu117\n",
      "2023-08-12 19:27:15,928 [INFO] >> cyto << model set to be used\n",
      "2023-08-12 19:27:15,932 [INFO] ** TORCH CUDA version installed and working. **\n",
      "2023-08-12 19:27:15,933 [INFO] >>>> using GPU\n",
      "2023-08-12 19:27:16,177 [INFO] >>>> model diam_mean =  30.000 (ROIs rescaled to this size during training)\n",
      "2023-08-12 19:27:50,133 [INFO] >>>> median diameter set to = 30\n",
      "2023-08-12 19:27:50,136 [INFO] >>>> mean of training label mask diameters (saved to model) 48.758\n",
      "2023-08-12 19:27:50,142 [INFO] >>>> training network with 2 channel input <<<<\n",
      "2023-08-12 19:27:50,143 [INFO] >>>> LR: 0.01000, batch_size: 8, weight_decay: 0.00010\n",
      "2023-08-12 19:27:50,143 [INFO] >>>> ntrain = 36, ntest = 12\n",
      "2023-08-12 19:27:50,144 [INFO] >>>> ntrain = 36\n",
      "2023-08-12 19:27:50,145 [INFO] >>>> nimg_per_epoch = 36\n",
      "2023-08-12 19:27:50,149 [INFO] Epoch 0/100::   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "2023-08-12 19:28:04,234 [INFO] Epoch 0/100::  20%|##        | 1/5 [00:14<00:56, 14.08s/it]\n",
      "2023-08-12 19:28:10,996 [INFO] Epoch 0/100::  40%|####      | 2/5 [00:20<00:29,  9.78s/it]\n",
      "2023-08-12 19:28:21,106 [INFO] Epoch 0/100::  60%|######    | 3/5 [00:30<00:19,  9.93s/it]\n",
      "2023-08-12 19:28:29,445 [INFO] Epoch 0/100::  80%|########  | 4/5 [00:39<00:09,  9.30s/it]\n",
      "2023-08-12 19:28:33,217 [INFO] Epoch 0/100:: 100%|##########| 5/5 [00:43<00:00,  7.31s/it]\n",
      "2023-08-12 19:28:33,254 [INFO] Epoch 0/100:: 100%|##########| 5/5 [00:43<00:00,  8.62s/it]\n",
      "2023-08-12 19:28:33,258 [INFO] Epoch 0/100::   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "2023-08-12 19:28:42,775 [INFO] Epoch 0/100::  50%|#####     | 1/2 [00:09<00:09,  9.52s/it]\n",
      "2023-08-12 19:28:47,394 [INFO] Epoch 0/100:: 100%|##########| 2/2 [00:14<00:00,  6.64s/it]\n",
      "2023-08-12 19:28:47,442 [INFO] Epoch 0/100:: 100%|##########| 2/2 [00:14<00:00,  7.09s/it]\n",
      "2023-08-12 19:28:47,443 [INFO] Epoch 0, Time 57.3s, Loss 3.5705, Loss Test 3.5178, LR 0.0000\n",
      "2023-08-12 19:28:47,444 [INFO] saving network parameters to ./models/single_cell_params_test.pt\n",
      "2023-08-12 19:28:47,520 [INFO] Epoch 1/100::   0%|          | 0/5 [00:00<?, ?it/s]\n",
      "2023-08-12 19:28:57,091 [INFO] Epoch 1/100::  20%|##        | 1/5 [00:09<00:38,  9.57s/it]\n",
      "2023-08-12 19:29:06,485 [INFO] Epoch 1/100::  40%|####      | 2/5 [00:18<00:28,  9.47s/it]\n"
     ]
    }
   ],
   "source": [
    "# start logger (to see training across epochs)\n",
    "logger = io.logger_setup()\n",
    "\n",
    "# DEFINE CELLPOSE MODEL (without size model)\n",
    "model = models.CellposeModel(gpu=use_GPU, model_type=initial_model)\n",
    "\n",
    "# set channels\n",
    "channels = [chan, chan2]\n",
    "\n",
    "new_model_path = model.train(train_ds, test_ds, save_path=model_dir, \n",
    "                              n_epochs=n_epochs,\n",
    "                              learning_rate=learning_rate, \n",
    "                              weight_decay=weight_decay, \n",
    "                              nimg_per_epoch=5,\n",
    "                              model_name=model_name,\n",
    "                              batch_size=8\n",
    "                              )\n",
    "\n",
    "# diameter of labels in training images\n",
    "diam_labels = model.diam_labels.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cdH0j8-L6FuB"
   },
   "source": [
    "## Evaluate on test data (optional)\n",
    "\n",
    "If you have test data, check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0AGsH5p6K6S",
    "outputId": "3f67063a-2197-4ec2-8619-0b52c98fd0ee"
   },
   "outputs": [],
   "source": [
    "# get files (during training, test_data is transformed so we will load it again)\n",
    "output = io.load_train_test_data(test_dir, mask_filter='_seg.npy')\n",
    "test_data, test_labels = output[:2]\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, \n",
    "                   channels=[chan, chan2],\n",
    "                   diameter=diam_labels)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print('')\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "K8tZ8uYR-IFW"
   },
   "source": [
    "plot masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z2ac5gtr-HPq",
    "outputId": "65c96437-85e4-42cf-8d4b-414b6ba98c0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,8), dpi=150)\n",
    "for k,im in enumerate(test_data):\n",
    "    img = im.copy()\n",
    "    plt.subplot(3,len(train_files), k+1)\n",
    "    img = np.vstack((img, np.zeros_like(img)[:1]))\n",
    "    img = img.transpose(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('image')\n",
    "\n",
    "    plt.subplot(3,len(train_files), len(train_files) + k+1)\n",
    "    plt.imshow(masks[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('predicted labels')\n",
    "\n",
    "    plt.subplot(3,len(train_files), 2*len(train_files) + k+1)\n",
    "    plt.imshow(test_labels[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('true labels')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tt8hgC7rniP8",
    "outputId": "677fa3d0-952f-4490-f5bb-4ef1ad0b0469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: nvcc: command not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Aug 12 15:35:21 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1060 6GB     On | 00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   49C    P0               35W / 180W|    828MiB /  6144MiB |      9%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2646      G   /usr/lib/xorg/Xorg                          309MiB |\n",
      "|    0   N/A  N/A      2795      G   /usr/bin/gnome-shell                         98MiB |\n",
      "|    0   N/A  N/A     31578      G   ...9860281,16491315440596507457,262144       30MiB |\n",
      "|    0   N/A  N/A     44422      G   ...sion,SpareRendererForSitePerProcess      385MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      ">>> GPU activated? YES\n"
     ]
    }
   ],
   "source": [
    "!nvcc --version\n",
    "!nvidia-smi\n",
    "\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cellpose import core, utils, io, models, metrics\n",
    "from glob import glob\n",
    "from data_loader import CellDataLoader, CellDataset\n",
    "\n",
    "use_GPU = core.use_gpu()\n",
    "yn = ['NO', 'YES']\n",
    "print(f'>>> GPU activated? {yn[use_GPU]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQI4aUxCjz3n",
    "outputId": "804d0459-b120-4298-9b4c-87a9ca26401c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default advanced parameters enabled\n"
     ]
    }
   ],
   "source": [
    "#@markdown ###Path to images and masks:\n",
    "\n",
    "train_dir = \"/media/balint/st1/data/cell-counting/annotated/\" #@param {type:\"string\"}\n",
    "test_dir = \"\" #@param {type:\"string\"}\n",
    "model_dir = \"./\"\n",
    "#Define where the patch file will be saved\n",
    "base = \"/content\"\n",
    "\n",
    "# model name and path\n",
    "#@markdown ###Name of the pretrained model to start from and new model name:\n",
    "from cellpose import models\n",
    "initial_model = \"cyto\" #@param ['cyto','nuclei','tissuenet','livecell','cyto2','CP','CPx','TN1','TN2','TN3','LC1','LC2','LC3','LC4','scratch']\n",
    "model_name = \"single_cell_params_test.pt\" #@param {type:\"string\"}\n",
    "\n",
    "# other parameters for training.\n",
    "#@markdown ###Training Parameters:\n",
    "#@markdown Number of epochs:\n",
    "n_epochs =  100#@param {type:\"number\"}\n",
    "\n",
    "Channel_to_use_for_training = \"Grayscale\" #@param [\"Grayscale\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "# @markdown ###If you have a secondary channel that can be used for training, for instance nuclei, choose it here:\n",
    "\n",
    "Second_training_channel= \"None\" #@param [\"None\", \"Blue\", \"Green\", \"Red\"]\n",
    "\n",
    "\n",
    "#@markdown ###Advanced Parameters\n",
    "\n",
    "Use_Default_Advanced_Parameters = True #@param {type:\"boolean\"}\n",
    "#@markdown ###If not, please input:\n",
    "learning_rate = 0.1 #@param {type:\"number\"}\n",
    "weight_decay = 0.0001 #@param {type:\"number\"}\n",
    "\n",
    "if (Use_Default_Advanced_Parameters): \n",
    "  print(\"Default advanced parameters enabled\")\n",
    "  learning_rate = 0.01 \n",
    "  weight_decay = 0.0001\n",
    "  \n",
    "#here we check that no model with the same name already exist, if so delete\n",
    "model_path = train_dir + 'models/'\n",
    "if os.path.exists(model_path+'/'+model_name):\n",
    "  print(\"!! WARNING: \"+model_name+\" already exists and will be deleted in the following cell !!\")\n",
    "  \n",
    "if len(test_dir) == 0:\n",
    "  test_dir = None\n",
    "\n",
    "# Here we match the channel to number\n",
    "if Channel_to_use_for_training == \"Grayscale\":\n",
    "  chan = 0\n",
    "elif Channel_to_use_for_training == \"Blue\":\n",
    "  chan = 3\n",
    "elif Channel_to_use_for_training == \"Green\":\n",
    "  chan = 2\n",
    "elif Channel_to_use_for_training == \"Red\":\n",
    "  chan = 1\n",
    "\n",
    "\n",
    "if Second_training_channel == \"Blue\":\n",
    "  chan2 = 3\n",
    "elif Second_training_channel == \"Green\":\n",
    "  chan2 = 2\n",
    "elif Second_training_channel == \"Red\":\n",
    "  chan2 = 1\n",
    "elif Second_training_channel == \"None\":\n",
    "  chan2 = 0\n",
    "\n",
    "if initial_model=='scratch':\n",
    "  initial_model = 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mQsv-Iz7m_CF",
    "outputId": "bef9d0e1-ca51-450c-8c60-856c3f545bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python -m cellpose --use_gpu --verbose --train --dir /media/balint/st1/data/cell-counting/annotated/ --pretrained_model cyto --chan 0 --chan2 0 --n_epochs 100 --learning_rate 0.01 --weight_decay 0.0001 --mask_filter _seg.npy\n"
     ]
    }
   ],
   "source": [
    "run_str = f'python -m cellpose --use_gpu --verbose --train --dir {train_dir} --pretrained_model {initial_model} --chan {chan} --chan2 {chan2} --n_epochs {n_epochs} --learning_rate {learning_rate} --weight_decay {weight_decay}'\n",
    "if test_dir is not None:\n",
    "    run_str += f' --test_dir {test_dir}'\n",
    "run_str += ' --mask_filter _seg.npy' # if you want to use _seg.npy files for training\n",
    "print(run_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = []\n",
    "with open(\"./file_paths.txt\", \"r\") as fp:\n",
    "    data_paths = fp.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CellDataset(data_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m nimg \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m      5\u001b[0m nimgt \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfor\u001b[39;00m imgi, lbl \u001b[39min\u001b[39;00m tr_loader:\n\u001b[1;32m      8\u001b[0m     nimg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m imgi\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m      9\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/cellpose/lib/python3.8/site-packages/torch/utils/data/dataloader.py:634\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    632\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    633\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    635\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    636\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    638\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/anaconda3/envs/cellpose/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1329\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_data(data)\n\u001b[1;32m   1328\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_shutdown \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m-> 1329\u001b[0m idx, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_data()\n\u001b[1;32m   1330\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tasks_outstanding \u001b[39m-\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1331\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable:\n\u001b[1;32m   1332\u001b[0m     \u001b[39m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cellpose/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1295\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[39m# In this case, `self._data_queue` is a `queue.Queue`,. But we don't\u001b[39;00m\n\u001b[1;32m   1292\u001b[0m     \u001b[39m# need to call `.task_done()` because we don't use `.join()`.\u001b[39;00m\n\u001b[1;32m   1293\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m-> 1295\u001b[0m         success, data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_get_data()\n\u001b[1;32m   1296\u001b[0m         \u001b[39mif\u001b[39;00m success:\n\u001b[1;32m   1297\u001b[0m             \u001b[39mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/cellpose/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1133\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1120\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_get_data\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m_utils\u001b[39m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[1;32m   1121\u001b[0m     \u001b[39m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[39m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[39m# Returns a 2-tuple:\u001b[39;00m\n\u001b[1;32m   1131\u001b[0m     \u001b[39m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1133\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_queue\u001b[39m.\u001b[39;49mget(timeout\u001b[39m=\u001b[39;49mtimeout)\n\u001b[1;32m   1134\u001b[0m         \u001b[39mreturn\u001b[39;00m (\u001b[39mTrue\u001b[39;00m, data)\n\u001b[1;32m   1135\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1136\u001b[0m         \u001b[39m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[1;32m   1137\u001b[0m         \u001b[39m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# worker failures.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/cellpose/lib/python3.8/multiprocessing/queues.py:107\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m block:\n\u001b[1;32m    106\u001b[0m     timeout \u001b[39m=\u001b[39m deadline \u001b[39m-\u001b[39m time\u001b[39m.\u001b[39mmonotonic()\n\u001b[0;32m--> 107\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout):\n\u001b[1;32m    108\u001b[0m         \u001b[39mraise\u001b[39;00m Empty\n\u001b[1;32m    109\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_poll():\n",
      "File \u001b[0;32m~/anaconda3/envs/cellpose/lib/python3.8/multiprocessing/connection.py:257\u001b[0m, in \u001b[0;36m_ConnectionBase.poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[1;32m    256\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_readable()\n\u001b[0;32m--> 257\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll(timeout)\n",
      "File \u001b[0;32m~/anaconda3/envs/cellpose/lib/python3.8/multiprocessing/connection.py:424\u001b[0m, in \u001b[0;36mConnection._poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_poll\u001b[39m(\u001b[39mself\u001b[39m, timeout):\n\u001b[0;32m--> 424\u001b[0m     r \u001b[39m=\u001b[39m wait([\u001b[39mself\u001b[39;49m], timeout)\n\u001b[1;32m    425\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(r)\n",
      "File \u001b[0;32m~/anaconda3/envs/cellpose/lib/python3.8/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/anaconda3/envs/cellpose/lib/python3.8/selectors.py:415\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    413\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    414\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 415\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    416\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tr_loader = CellDataLoader(train_ds, 2, True, True, 0.2, num_workers=2)\n",
    "tst_loader = tr_loader.split_validation()\n",
    "\n",
    "nimg = 0\n",
    "nimgt = 0\n",
    "\n",
    "for imgi, lbl in tr_loader:\n",
    "    nimg += imgi.shape[0]\n",
    "print('\\n')\n",
    "for imgi, lbl in tst_loader:\n",
    "    nimgt += imgi.shape[0]\n",
    "print(nimg, nimgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcYskYudMajM",
    "outputId": "ed4dce67-190e-4d52-9a70-bcbc76be4b65"
   },
   "outputs": [],
   "source": [
    "# start logger (to see training across epochs)\n",
    "logger = io.logger_setup()\n",
    "\n",
    "# DEFINE CELLPOSE MODEL (without size model)\n",
    "model = models.CellposeModel(gpu=use_GPU, model_type=initial_model)\n",
    "\n",
    "# set channels\n",
    "channels = [chan, chan2]\n",
    "\n",
    "new_model_path = model.train(train_ds, save_path=model_dir, \n",
    "                              n_epochs=n_epochs,\n",
    "                              learning_rate=learning_rate, \n",
    "                              weight_decay=weight_decay, \n",
    "                              nimg_per_epoch=5,\n",
    "                              model_name=model_name,\n",
    "                              )\n",
    "\n",
    "# diameter of labels in training images\n",
    "diam_labels = model.diam_labels.copy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "cdH0j8-L6FuB"
   },
   "source": [
    "## Evaluate on test data (optional)\n",
    "\n",
    "If you have test data, check performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0AGsH5p6K6S",
    "outputId": "3f67063a-2197-4ec2-8619-0b52c98fd0ee"
   },
   "outputs": [],
   "source": [
    "# get files (during training, test_data is transformed so we will load it again)\n",
    "output = io.load_train_test_data(test_dir, mask_filter='_seg.npy')\n",
    "test_data, test_labels = output[:2]\n",
    "\n",
    "# run model on test images\n",
    "masks = model.eval(test_data, \n",
    "                   channels=[chan, chan2],\n",
    "                   diameter=diam_labels)[0]\n",
    "\n",
    "# check performance using ground truth labels\n",
    "ap = metrics.average_precision(test_labels, masks)[0]\n",
    "print('')\n",
    "print(f'>>> average precision at iou threshold 0.5 = {ap[:,0].mean():.3f}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "K8tZ8uYR-IFW"
   },
   "source": [
    "plot masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Z2ac5gtr-HPq",
    "outputId": "65c96437-85e4-42cf-8d4b-414b6ba98c0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(12,8), dpi=150)\n",
    "for k,im in enumerate(test_data):\n",
    "    img = im.copy()\n",
    "    plt.subplot(3,len(train_files), k+1)\n",
    "    img = np.vstack((img, np.zeros_like(img)[:1]))\n",
    "    img = img.transpose(1,2,0)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('image')\n",
    "\n",
    "    plt.subplot(3,len(train_files), len(train_files) + k+1)\n",
    "    plt.imshow(masks[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('predicted labels')\n",
    "\n",
    "    plt.subplot(3,len(train_files), 2*len(train_files) + k+1)\n",
    "    plt.imshow(test_labels[k])\n",
    "    plt.axis('off')\n",
    "    if k==0:\n",
    "        plt.title('true labels')\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
